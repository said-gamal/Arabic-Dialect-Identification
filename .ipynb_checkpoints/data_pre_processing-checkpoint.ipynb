{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from maha.cleaners.functions import keep, normalize, remove_tatweel, reduce_repeated_substring # for text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialect_df = pd.read_csv('fetched_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dialect</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1175358310087892992</td>\n",
       "      <td>IQ</td>\n",
       "      <td>@Nw8ieJUwaCAAreT Ù„ÙƒÙ† Ø¨Ø§Ù„Ù†Ù‡Ø§ÙŠØ© .. ÙŠÙ†ØªÙØ¶ .. ÙŠØºÙŠØ± .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1175416117793349632</td>\n",
       "      <td>IQ</td>\n",
       "      <td>@7zNqXP0yrODdRjK ÙŠØ¹Ù†ÙŠ Ù‡Ø°Ø§ Ù…Ø­Ø³ÙˆØ¨ Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ø´Ø± .. Ø­...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1175450108898565888</td>\n",
       "      <td>IQ</td>\n",
       "      <td>@KanaanRema Ù…Ø¨ÙŠÙ† Ù…Ù† ÙƒÙ„Ø§Ù…Ù‡ Ø®Ù„ÙŠØ¬ÙŠ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1175471073770573824</td>\n",
       "      <td>IQ</td>\n",
       "      <td>@HAIDER76128900 ÙŠØ³Ù„Ù…Ù„ÙŠ Ù…Ø±ÙˆØ±Ùƒ ÙˆØ±ÙˆØ­Ùƒ Ø§Ù„Ø­Ù„ÙˆÙ‡ğŸ’</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1175496913145217024</td>\n",
       "      <td>IQ</td>\n",
       "      <td>@hmo2406 ÙˆÙŠÙ† Ù‡Ù„ Ø§Ù„ØºÙŠØ¨Ù‡  Ø§Ø® Ù…Ø­Ù…Ø¯ ğŸŒ¸ğŸŒº</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458192</th>\n",
       "      <td>1019484980282580992</td>\n",
       "      <td>BH</td>\n",
       "      <td>@Al_mhbaa_7 Ù…Ø¨Ø³ÙˆØ·ÙŠÙ† Ù…Ù†Ùƒ Ø§Ù„Ù„ÙŠ Ø¨Ø§Ø³Ø·Ø§Ù†Ø§ğŸ˜…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458193</th>\n",
       "      <td>1021083283709407232</td>\n",
       "      <td>BH</td>\n",
       "      <td>@Zzainabali @P_ameerah ÙˆØ§Ù„Ù„Ù‡ Ù…Ø§ÙŠÙ†Ø¯Ù‡ Ø§Ø¨Ø´ ÙŠØ®ØªÙŠ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458194</th>\n",
       "      <td>1017477537889431552</td>\n",
       "      <td>BH</td>\n",
       "      <td>@Al_mhbaa_7 Ø´Ùˆ Ø¹Ù…Ù„Ù†Ø§ Ù„Ùƒ Ø­Ù†Ø§ ØªÙ‡Ø±Ø¨ÙŠ Ù…Ù†Ù†Ø§ Ø§Ø­Ù†Ø§ Ù…Ø³...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458195</th>\n",
       "      <td>1022430374696239232</td>\n",
       "      <td>BH</td>\n",
       "      <td>@haneenalmwla Ø§Ù„Ù„Ù‡ ÙŠØ¨Ø§Ø±Ùƒ ÙÙŠÙ‡Ø§ ÙˆØ¨Ø§Ù„Ø¹Ø§ÙÙŠÙ‡ ğŸ˜‹ğŸ˜‹ğŸ˜‹</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458196</th>\n",
       "      <td>1022409931029458944</td>\n",
       "      <td>BH</td>\n",
       "      <td>@jolnar121 Ø§Ù„Ø³Ø­Ù„Ù‡ Ø¶ÙŠÙÙŠ ÙŠ Ø¨ØªØ·Ù„Ø¹ Ù„Ùƒ Ø³Ø­Ù„ÙŠÙ‡ğŸ˜…ğŸ˜…</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>458197 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id dialect  \\\n",
       "0       1175358310087892992      IQ   \n",
       "1       1175416117793349632      IQ   \n",
       "2       1175450108898565888      IQ   \n",
       "3       1175471073770573824      IQ   \n",
       "4       1175496913145217024      IQ   \n",
       "...                     ...     ...   \n",
       "458192  1019484980282580992      BH   \n",
       "458193  1021083283709407232      BH   \n",
       "458194  1017477537889431552      BH   \n",
       "458195  1022430374696239232      BH   \n",
       "458196  1022409931029458944      BH   \n",
       "\n",
       "                                                    tweet  \n",
       "0        @Nw8ieJUwaCAAreT Ù„ÙƒÙ† Ø¨Ø§Ù„Ù†Ù‡Ø§ÙŠØ© .. ÙŠÙ†ØªÙØ¶ .. ÙŠØºÙŠØ± .  \n",
       "1       @7zNqXP0yrODdRjK ÙŠØ¹Ù†ÙŠ Ù‡Ø°Ø§ Ù…Ø­Ø³ÙˆØ¨ Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ø´Ø± .. Ø­...  \n",
       "2                         @KanaanRema Ù…Ø¨ÙŠÙ† Ù…Ù† ÙƒÙ„Ø§Ù…Ù‡ Ø®Ù„ÙŠØ¬ÙŠ  \n",
       "3              @HAIDER76128900 ÙŠØ³Ù„Ù…Ù„ÙŠ Ù…Ø±ÙˆØ±Ùƒ ÙˆØ±ÙˆØ­Ùƒ Ø§Ù„Ø­Ù„ÙˆÙ‡ğŸ’  \n",
       "4                      @hmo2406 ÙˆÙŠÙ† Ù‡Ù„ Ø§Ù„ØºÙŠØ¨Ù‡  Ø§Ø® Ù…Ø­Ù…Ø¯ ğŸŒ¸ğŸŒº  \n",
       "...                                                   ...  \n",
       "458192              @Al_mhbaa_7 Ù…Ø¨Ø³ÙˆØ·ÙŠÙ† Ù…Ù†Ùƒ Ø§Ù„Ù„ÙŠ Ø¨Ø§Ø³Ø·Ø§Ù†Ø§ğŸ˜…  \n",
       "458193       @Zzainabali @P_ameerah ÙˆØ§Ù„Ù„Ù‡ Ù…Ø§ÙŠÙ†Ø¯Ù‡ Ø§Ø¨Ø´ ÙŠØ®ØªÙŠ  \n",
       "458194  @Al_mhbaa_7 Ø´Ùˆ Ø¹Ù…Ù„Ù†Ø§ Ù„Ùƒ Ø­Ù†Ø§ ØªÙ‡Ø±Ø¨ÙŠ Ù…Ù†Ù†Ø§ Ø§Ø­Ù†Ø§ Ù…Ø³...  \n",
       "458195        @haneenalmwla Ø§Ù„Ù„Ù‡ ÙŠØ¨Ø§Ø±Ùƒ ÙÙŠÙ‡Ø§ ÙˆØ¨Ø§Ù„Ø¹Ø§ÙÙŠÙ‡ ğŸ˜‹ğŸ˜‹ğŸ˜‹  \n",
       "458196          @jolnar121 Ø§Ù„Ø³Ø­Ù„Ù‡ Ø¶ÙŠÙÙŠ ÙŠ Ø¨ØªØ·Ù„Ø¹ Ù„Ùƒ Ø³Ø­Ù„ÙŠÙ‡ğŸ˜…ğŸ˜…  \n",
       "\n",
       "[458197 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialect_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean tweets from non-arabic letters and emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_chars = ['Ù»', 'Û‚', 'Ù¸', 'Û', 'Ù²', 'Û‘', 'Ú£', 'Û‡', 'Û', 'Ù¶', 'Úª', 'Úº', 'Ú¯', 'Ú', 'Ù±', 'ÛŒ', 'Ú‰', 'Û„', 'Ú›', 'á“…', 'Úˆ',\n",
    " 'Û¿', 'Ú©', 'Úµ', 'Ú¤', 'Û¼', 'Ú²', 'Ú†', 'Ú', 'Ùº', 'Ú¨', 'Ú‡', 'Û…', 'Ûƒ', '×¤', 'Ú»', 'Ú˜', 'Ú³', 'İ ', 'Ù¾', 'Û†', 'Û‰', 'Û€',\n",
    " 'Ûˆ', 'Ú’', 'Ú¹', 'Ù¼', 'Ú¥', 'Û', 'Ú±', 'Ú¾', 'Ã¶', 'Ú', 'İ£', 'Ú°', 'Ú•', 'Ú¦', 'Û‹', 'Ú·', 'ÚŠ', 'Ú“', 'Ú­', 'Úœ', 'Ú¼', 'Û']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "arabic_chars = ['Ø¨', 'Ù‡', 'ÙŠ', 'Ù‡', 'Ø§', 'ÙŠ', 'Ù', 'Ùˆ', 'ÙŠ', 'Ùˆ', 'Ùƒ', 'Ù†', 'Ùƒ', 'Ø¯', 'Ø§', 'ÙŠ', 'Ø¯', 'Ùˆ', 'Ø³', 'Ù', 'Ø°',\n",
    " 'Ù‡', 'Ùƒ', 'Ù„', 'Ù‚', 'Øº', 'Ùƒ', 'Ø¬', 'Øµ', 'Ù†', 'Ù‚', 'Ø¬', 'Ùˆ', 'Ù‡', 'Ùˆ', 'Ù†', 'Ø²', 'Ùƒ', 'Ù', 'Ø¨', 'Ùˆ', 'Ùˆ', 'Ù‡',\n",
    " 'Ùˆ', 'Ø²', 'Ù†', 'Øª', 'Ù', 'ÙŠ', 'Ùƒ', 'Ù‡', 'Ù‡', 'Ø°', 'Ùƒ', 'Ùƒ', 'Ø±', 'Ù‚', 'Ùˆ', 'Ù„', 'Ø¯', 'Ø±', 'Ùƒ', 'Ø´', 'Ù†', 'ÙŠ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace non-arabic to arabic chars\n",
    "chars_table = {ord(special_chars[i]): arabic_chars[i] for i in range(len(special_chars))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialect_df['tweet'] = dialect_df['tweet'].apply(lambda tweet: tweet.translate(chars_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(tweet):\n",
    "    tweet = tweet.replace('\\n', ' ')\n",
    "    tweet = keep(tweet, arabic=True, arabic_letters=True) # remove any non-arabic text\n",
    "    tweet = normalize(tweet, all=True) # normalize arabic letters (like: alef, teh-marbouta...)\n",
    "    tweet = remove_tatweel(tweet) # remove tatweel like ('Ø§Ù‡Ù€Ù€Ù€Ù€Ù€Ù€Ù„Ø§') to ('Ø§Ù‡Ù„Ø§')\n",
    "    tweet = reduce_repeated_substring(tweet, min_repeated=4, reduce_to=3) # reduce repeated chars like ('Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡') to ('Ù‡Ù‡Ù‡')\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialect_df['tweet'] = dialect_df['tweet'].apply(clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ù„ÙƒÙ† Ø¨Ø§Ù„Ù†Ù‡Ø§ÙŠÙ‡ ÙŠÙ†ØªÙØ¶ ÙŠØºÙŠØ±',\n",
       "       'ÙŠØ¹Ù†ÙŠ Ù‡Ø°Ø§ Ù…Ø­Ø³ÙˆØ¨ Ø¹Ù„ÙŠ Ø§Ù„Ø¨Ø´Ø± Ø­ÙŠÙˆÙ†Ù‡ ÙˆÙˆØ­Ø´ÙŠÙ‡ ÙˆØªØ·Ù„Ø¨ÙˆÙ† Ù…Ù† Ø§Ù„ØºØ±Ø¨ ÙŠØ­ØªØ±Ù…ÙƒÙ… ÙˆÙŠÙˆÙ…Ù† Ø¨Ø¯ÙŠÙ†ÙƒÙ… ÙˆÙ„Ø§ÙŠÙ†Ø¹ØªÙƒÙ… Ø¨Ø§Ù„Ø§Ø±Ù‡Ø§Ø¨',\n",
       "       'Ù…Ø¨ÙŠÙ† Ù…Ù† ÙƒÙ„Ø§Ù…Ù‡ Ø®Ù„ÙŠØ¬ÙŠ', 'ÙŠØ³Ù„Ù…Ù„ÙŠ Ù…Ø±ÙˆØ±Ùƒ ÙˆØ±ÙˆØ­Ùƒ Ø§Ù„Ø­Ù„ÙˆÙ‡',\n",
       "       'ÙˆÙŠÙ† Ù‡Ù„ Ø§Ù„ØºÙŠØ¨Ù‡ Ø§Ø® Ù…Ø­Ù…Ø¯',\n",
       "       'ÙŠØ§Ø§Ø®ÙŠ Ø§Ù„Ø§Ø±Ù‡Ø§Ø¨ÙŠ Ø§Ø°Ø§ ÙƒØ§Ù† Ø¹Ø±Ø§Ù‚ÙŠ Ø³Ø¹ÙˆØ¯ÙŠ ÙÙ„Ø³Ø·ÙŠÙ†ÙŠ ÙˆÙŠÙ† Ø§Ù„Ù…Ø´ÙƒÙ„Ù‡ Ø¹Ù„ÙŠ Ø¨Ø§Ø¨ Ø§Ù„ÙØ±Ø¶ Ø®Ù„ÙŠØ¬ÙŠ ÙˆÙ…Ø§Ø¹Ù†Ø¯Ù‡ Ø±Ø­Ù…Ù‡ ÙˆÙŠÙ† Ø§Ù„Ù…Ø³Ø§Ø³ Ø¨Ù‚Ø¯Ø³ÙŠØªÙƒ Ø§Ù„Ù„Ù‡ ÙŠØ±Ø¶ÙŠ Ø¹Ù†Ùƒ Ø®Ù„ØµØª Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø¹Ø±Ø¨ ÙˆØ§Ø®ØªÙ„ÙÙ†Ø§ Ø¨Ø¬Ù†Ø³ÙŠØª Ø§Ø¨Ùˆ Ø§Ù„Ø·ÙÙ„ Ø§Ù„Ù…ØºØ±Ø¯ÙŠÙ† Ø³Ø§Ù„ÙˆØ§ Ù…Ù† ÙˆÙŠÙ† ÙˆØ±Ø¬Ø­Øª ÙˆÙŠÙ† Ø§Ù„ÙƒØ§Ø±Ø«Ù‡ Ø§Ù„Ù„ÙŠ ÙˆØµÙ„ØªÙƒ',\n",
       "       'Ù…Ø·Ù„Ø¨ÙŠ ÙŠÙ‚Ø¯Ù… Ø§Ø³ØªÙ‚Ø§Ù„ØªÙ‡ ÙˆÙÙˆÙƒØ§Ù‡Ø§ Ø§Ø¹ØªØ°Ø§Ø±',\n",
       "       'Ø®Ù„Øµ ÙˆØ§Ù„Ù„Ù‡ Ù„Ø¹ÙŠÙˆÙ†ÙƒÙ… Ø§Ù†Ø§ Ù…Ø§Ø¹Ù†Ø¯ÙŠ Ø´ÙŠØ¡ Ù…Ø¹Ù‡ Ø¨Ø§Ù„Ø¹ÙƒØ³ Ù…Ù† Ù…ØªØ§Ø¨Ø¹ÙŠÙ†ÙŠ Ø§Ù„Ù„ÙŠ Ø¨Ø¹ØªØ² ÙÙŠÙ‡Ù… Ø®Ù„Øµ ØµØ§ÙÙŠÙ‡ Ù„Ø¨Ù†',\n",
       "       'ÙŠÙ…ÙƒÙ† Ø³ÙˆØ§Ù„ ÙØ§Øª Ø§Ù„ÙƒØ«ÙŠØ± Ø§Ù„Ù„ÙŠ ÙŠØµÙˆØ± Ø´Ù†Ùˆ Ù…ÙˆÙ‚ÙÙ‡ ÙˆÙƒØ§Ù†Ù‡ ÙŠÙˆØ«Ù‚ Ø¨Ø·ÙˆÙ„Ù‡ Ø§Ù„Ù…ÙØ±ÙˆØ¶ Ø­ØªÙŠ Ø§Ù„Ù…ØµÙˆØ± ÙŠØ­Ø§Ù„ Ù„Ù„Ù‚Ø¶Ø§Ø¡ Ù„Ø§Ù† Ù†Ø¸Ø±Ø§Øª Ø§Ù„Ø·ÙÙ„Ù‡ ØªØ³ØªÙ†Ø¬Ø¯ Ø¨Ø§ØªØ¬Ø§Ù‡ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§',\n",
       "       'Ø§ÙˆÙ„Ø§ Ø§Ù†ÙŠ Ø±Ø¯Øª Ø¹Ù„ÙŠ Ø±Ø¬Ù„ Ø¬Ù†ÙˆØ¨ÙŠ ÙˆØ§Ù„Ù„ÙŠ Ø°ÙƒØ± Ø­Ø¬Ø§Ø¨Ù‡Ø§ Ø«Ø§Ù†ÙŠØ§Ù‹ Ø§Ù†Øª Ø´Ø¯Ø¹ÙˆÙ‡ ØµØ§ÙŠØ±Ù‡ Ù…Ø­Ø§Ù…ÙŠ Ù„ÙƒÙˆÙ‡ÙŠÙ† ØµØ­ÙŠØ­ Ù…Ù‚ÙˆÙ„Ù‡ Ø§Ù„Ø¹Ø±Ø§Ù‚ Ø¨Ù„Ø¯ Ø§Ù„ØºØ±Ø§ÙŠØ¨ ÙˆØ§Ù„Ø¹Ø¬Ø§ÙŠØ¨'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialect_df['tweet'].iloc[:10].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check data imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EG    57636\n",
       "PL    43742\n",
       "KW    42109\n",
       "LY    36499\n",
       "QA    31069\n",
       "JO    27921\n",
       "LB    27617\n",
       "SA    26832\n",
       "AE    26296\n",
       "BH    26292\n",
       "OM    19116\n",
       "SY    16242\n",
       "DZ    16183\n",
       "IQ    15497\n",
       "SD    14434\n",
       "MA    11539\n",
       "YE     9927\n",
       "TN     9246\n",
       "Name: dialect, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialect_df['dialect'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dialect_df['dialect'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate text from tweets to make data balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweets_to_text(country_code):\n",
    "    return ' '.join(dialect_df[dialect_df['dialect'] == country_code]['tweet'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn_text = tweets_to_text('TN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "690961"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tn_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ù†Ø§Ø³ Ø¨ÙƒØ±ÙŠ Ù‚Ø§Ù„ÙˆØ§ Ø·ÙŠØ­ ÙˆØ´ÙˆÙ Ø´ÙƒÙˆÙ† ÙŠÙˆÙ‚Ù Ù…Ø¹Ø§Ùƒ ØºÙŠØ¨ ÙˆØ´ÙˆÙ Ø´ÙƒÙˆÙ† ÙŠØ³Ø§Ù„ Ø¹Ù„ÙŠÙƒ Ùˆ Ø¨Ø¹Ø¯ ØºØ±Ø¨Ù„ Ùˆ ØµÙÙŠ Ù…Ø«Ù„ Ø´Ø¹Ø¨ÙŠ ØªÙˆÙ†Ø³ÙŠ ØªÙˆÙ†Ø³ Ø§Ù„Ù…Ø²ÙŠØ§Ù†Ù‡ ØªÙ‡Ø¨Ù„ ÙˆØ§Ù„Ù„Ù‡ ÙÙ†Ø§Ù†Ù‡ Ù…Ø¨Ø¯Ø¹Ù‡ Ø§Ù†Øª Ù…Ø§Ø´Ø§Ø¡ Ø§Ù„Ù„Ù‡ Ø§Ù„Ù„Ù‡ ÙŠØ¨Ø§Ø±Ùƒ ÙÙŠÙƒ ÙŠØ¹ÙŠØ´Ùƒ Ø¹ÙŠØ¯ÙƒÙ… Ù…Ø¨Ø±ÙˆÙƒ ÙˆØ³Ù†ÙŠÙ† Ø¯Ø§ÙŠÙ…Ù‡ Ø¯Ù„ÙˆØ¹ Ø§Ù„Ù„'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn_text[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn_vocab = sorted(set(tn_text.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx = {char:index for index, char in enumerate(tn_vocab)}\n",
    "idx2char = np.array(tn_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_as_int = np.array([char2idx[char] for char in tn_text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 3\n",
    "examples_per_epoch = len(tn_text.split())//seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ù†Ø§Ø³\n",
      "Ø¨ÙƒØ±ÙŠ\n",
      "Ù‚Ø§Ù„ÙˆØ§\n",
      "Ø·ÙŠØ­\n",
      "ÙˆØ´ÙˆÙ\n",
      "Ø´ÙƒÙˆÙ†\n",
      "ÙŠÙˆÙ‚Ù\n",
      "Ù…Ø¹Ø§Ùƒ\n",
      "ØºÙŠØ¨\n",
      "ÙˆØ´ÙˆÙ\n"
     ]
    }
   ],
   "source": [
    "for i in char_dataset.take(10):\n",
    "    print(idx2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Ù†Ø§Ø³ Ø¨ÙƒØ±ÙŠ Ù‚Ø§Ù„ÙˆØ§ Ø·ÙŠØ­'\n",
      "'ÙˆØ´ÙˆÙ Ø´ÙƒÙˆÙ† ÙŠÙˆÙ‚Ù Ù…Ø¹Ø§Ùƒ'\n",
      "'ØºÙŠØ¨ ÙˆØ´ÙˆÙ Ø´ÙƒÙˆÙ† ÙŠØ³Ø§Ù„'\n",
      "'Ø¹Ù„ÙŠÙƒ Ùˆ Ø¨Ø¹Ø¯ ØºØ±Ø¨Ù„'\n",
      "'Ùˆ ØµÙÙŠ Ù…Ø«Ù„ Ø´Ø¹Ø¨ÙŠ'\n",
      "'ØªÙˆÙ†Ø³ÙŠ ØªÙˆÙ†Ø³ Ø§Ù„Ù…Ø²ÙŠØ§Ù†Ù‡ ØªÙ‡Ø¨Ù„'\n",
      "'ÙˆØ§Ù„Ù„Ù‡ ÙÙ†Ø§Ù†Ù‡ Ù…Ø¨Ø¯Ø¹Ù‡ Ø§Ù†Øª'\n",
      "'Ù…Ø§Ø´Ø§Ø¡ Ø§Ù„Ù„Ù‡ Ø§Ù„Ù„Ù‡ ÙŠØ¨Ø§Ø±Ùƒ'\n",
      "'ÙÙŠÙƒ ÙŠØ¹ÙŠØ´Ùƒ Ø¹ÙŠØ¯ÙƒÙ… Ù…Ø¨Ø±ÙˆÙƒ'\n",
      "'ÙˆØ³Ù†ÙŠÙ† Ø¯Ø§ÙŠÙ…Ù‡ Ø¯Ù„ÙˆØ¹ Ø§Ù„Ù„Ù‡'\n"
     ]
    }
   ],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "# Try 10\n",
    "for item in sequences.take(10):\n",
    "    print(repr(' '.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  'Ù†Ø§Ø³ Ø¨ÙƒØ±ÙŠ Ù‚Ø§Ù„ÙˆØ§'\n",
      "Target data: 'Ø¨ÙƒØ±ÙŠ Ù‚Ø§Ù„ÙˆØ§ Ø·ÙŠØ­'\n",
      "Input data:  'ÙˆØ´ÙˆÙ Ø´ÙƒÙˆÙ† ÙŠÙˆÙ‚Ù'\n",
      "Target data: 'Ø´ÙƒÙˆÙ† ÙŠÙˆÙ‚Ù Ù…Ø¹Ø§Ùƒ'\n",
      "Input data:  'ØºÙŠØ¨ ÙˆØ´ÙˆÙ Ø´ÙƒÙˆÙ†'\n",
      "Target data: 'ÙˆØ´ÙˆÙ Ø´ÙƒÙˆÙ† ÙŠØ³Ø§Ù„'\n",
      "Input data:  'Ø¹Ù„ÙŠÙƒ Ùˆ Ø¨Ø¹Ø¯'\n",
      "Target data: 'Ùˆ Ø¨Ø¹Ø¯ ØºØ±Ø¨Ù„'\n",
      "Input data:  'Ùˆ ØµÙÙŠ Ù…Ø«Ù„'\n",
      "Target data: 'ØµÙÙŠ Ù…Ø«Ù„ Ø´Ø¹Ø¨ÙŠ'\n",
      "Input data:  'ØªÙˆÙ†Ø³ÙŠ ØªÙˆÙ†Ø³ Ø§Ù„Ù…Ø²ÙŠØ§Ù†Ù‡'\n",
      "Target data: 'ØªÙˆÙ†Ø³ Ø§Ù„Ù…Ø²ÙŠØ§Ù†Ù‡ ØªÙ‡Ø¨Ù„'\n",
      "Input data:  'ÙˆØ§Ù„Ù„Ù‡ ÙÙ†Ø§Ù†Ù‡ Ù…Ø¨Ø¯Ø¹Ù‡'\n",
      "Target data: 'ÙÙ†Ø§Ù†Ù‡ Ù…Ø¨Ø¯Ø¹Ù‡ Ø§Ù†Øª'\n",
      "Input data:  'Ù…Ø§Ø´Ø§Ø¡ Ø§Ù„Ù„Ù‡ Ø§Ù„Ù„Ù‡'\n",
      "Target data: 'Ø§Ù„Ù„Ù‡ Ø§Ù„Ù„Ù‡ ÙŠØ¨Ø§Ø±Ùƒ'\n",
      "Input data:  'ÙÙŠÙƒ ÙŠØ¹ÙŠØ´Ùƒ Ø¹ÙŠØ¯ÙƒÙ…'\n",
      "Target data: 'ÙŠØ¹ÙŠØ´Ùƒ Ø¹ÙŠØ¯ÙƒÙ… Ù…Ø¨Ø±ÙˆÙƒ'\n",
      "Input data:  'ÙˆØ³Ù†ÙŠÙ† Ø¯Ø§ÙŠÙ…Ù‡ Ø¯Ù„ÙˆØ¹'\n",
      "Target data: 'Ø¯Ø§ÙŠÙ…Ù‡ Ø¯Ù„ÙˆØ¹ Ø§Ù„Ù„Ù‡'\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset.take(10):\n",
    "    print ('Input data: ', repr(' '.join(idx2char[input_example.numpy()])))\n",
    "    print ('Target data:', repr(' '.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tn_vocab)\n",
    "embedding_dim = 256\n",
    "rnn_units = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n",
    "        tf.keras.layers.GRU(rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(vocab_size=vocab_size, embedding_dim=embedding_dim, rnn_units=rnn_units, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 3, 34366) # (batch_size, sequence_length, vocab_size)\n",
      "(64, 3, 34366) # (batch_size, sequence_length, vocab_size)\n",
      "(64, 3, 34366) # (batch_size, sequence_length, vocab_size)\n",
      "(64, 3, 34366) # (batch_size, sequence_length, vocab_size)\n",
      "(64, 3, 34366) # (batch_size, sequence_length, vocab_size)\n",
      "(64, 3, 34366) # (batch_size, sequence_length, vocab_size)\n",
      "(64, 3, 34366) # (batch_size, sequence_length, vocab_size)\n",
      "(64, 3, 34366) # (batch_size, sequence_length, vocab_size)\n",
      "(64, 3, 34366) # (batch_size, sequence_length, vocab_size)\n",
      "(64, 3, 34366) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(10):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (64, None, 256)           8797696   \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (64, None, 256)           394752    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (64, None, 34366)         8832062   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,024,510\n",
      "Trainable params: 18,024,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13259, 31841, 13204], dtype=int64)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([ 2858, 28012, 27832])>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_example_batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " 'Ø§Ù„ØªÙˆÙ†Ø³ÙŠÙ‡ Ùˆ Ù‡Ù†Ø¯'\n",
      "\n",
      "Next Char Predictions: \n",
      " 'Ø­Ø²Ø§Ù†Ø§ ÙŠØ§Ø¹Ù…Ø±ÙŠ Ø­Ø±Ø§Ø¨Ø´'\n"
     ]
    }
   ],
   "source": [
    "print(\"Input: \\n\", repr(\" \".join(idx2char[input_example_batch[0].numpy()])))\n",
    "print()\n",
    "print(\"Next Char Predictions: \\n\", repr(\" \".join(idx2char[sampled_indices])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 3, 34366)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       10.44485\n"
     ]
    }
   ],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "514/514 [==============================] - 9s 15ms/step - loss: 9.3215\n",
      "Epoch 2/10\n",
      "514/514 [==============================] - 8s 15ms/step - loss: 8.4715\n",
      "Epoch 3/10\n",
      "514/514 [==============================] - 8s 15ms/step - loss: 7.9700\n",
      "Epoch 4/10\n",
      "514/514 [==============================] - 8s 15ms/step - loss: 7.2435\n",
      "Epoch 5/10\n",
      "514/514 [==============================] - 8s 15ms/step - loss: 6.4122\n",
      "Epoch 6/10\n",
      "514/514 [==============================] - 8s 15ms/step - loss: 5.5765\n",
      "Epoch 7/10\n",
      "514/514 [==============================] - 8s 15ms/step - loss: 4.8204\n",
      "Epoch 8/10\n",
      "514/514 [==============================] - 8s 15ms/step - loss: 4.1814\n",
      "Epoch 9/10\n",
      "514/514 [==============================] - 8s 15ms/step - loss: 3.6800\n",
      "Epoch 10/10\n",
      "514/514 [==============================] - 8s 15ms/step - loss: 3.3006\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./training_checkpoints\\\\ckpt_10'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "    # Evaluation step (generating text using the learned model)\n",
    "\n",
    "    # Number of characters to generate\n",
    "    num_generate = 5\n",
    "\n",
    "    # Converting our start string to numbers (vectorizing)\n",
    "    input_eval = [np.random.randint(0, len(tn_vocab))]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    # Empty string to store our results\n",
    "    text_generated = []\n",
    "\n",
    "    # Low temperatures results in more predictable text.\n",
    "    # Higher temperatures results in more surprising text.\n",
    "    # Experiment to find the best setting.\n",
    "    temperature = 1.0\n",
    "\n",
    "    # Here batch size == 1\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        # remove the batch dimension\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "        # using a categorical distribution to predict the word returned by the model\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "        # We pass the predicted word as the next input to the model\n",
    "        # along with the previous hidden state\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "    return (start_string + ' '.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÙÙ‚Ø¯Ø§Ù†Ùˆ Ù…Ù† Ø§Ù„Ù…ÙØ±ÙˆØ¶ Ø§Ù„Ù†Ø§Ø³ ÙˆØªØ´Ø¨Ø«\n",
      "Ø­ÙŠØ®Ù„ÙŠÙ‡Ø§ Ø¹Ù‚Ù„Ø§Ù†ÙŠÙˆÙ† Ù…Ø¹ÙÙ†ÙŠÙ† Ø§Ù†Øª Ù†ØªØ¨Ø¹\n",
      "ØºÙ„Ø· Ù…Ù†ÙŠÙ† ÙŠØ¬ÙŠ Ø§Ù„Ù…Ù‡Ø¯ÙŠ Ø§Ù„Ù…Ù†ØªØ¸Ø±\n",
      "Ø¹Ø´Ø±Ø§Øª Ù„ÙƒÙ† Ù…Ø´ Ø±Ø§Ø¬Ù„ ÙŠØ§Ø±Ø¨\n",
      "Ù‡Ø°Ù‡ ÙƒØ¨ÙŠØ± Ø¨Ø§Ø´ Ù†Ø®Ø±Ø¬ Ø§Ù„Ø¬Ø±Ø§ÙŠÙ‡\n",
      "ÙŠØ³Ù„Ù…Ùƒ ÙˆÙŠØ³Ø¹Ø¯ Ù‚Ù„Ø¨Ùƒ Ù†Ù†ÙˆØ³ ÙˆØ§Ù†ÙŠ\n",
      "Ù†Ø­Ø§Ù„Ùˆ Ø¬Ø¯ Ø¹Ù„ÙŠÙƒ Ø¨Ø§Ù‚ÙŠ ØµØ±ÙŠØ­\n",
      "Ø¨Ø§Ù„Ù‡Ø¨ÙˆÙˆÙˆØ· Ù‚Ø¯Ø§Ø´ ØµØ§Ø¯Ù… Ùˆ ÙˆÙ‚Ø­\n",
      "Ù‚Ø±Ø§ ÙØ±ÙŠÙƒÙˆÙ†Ø³ Ù†Ø§Ø³ Ù…Ù„Ø§Ø­ ÙŠØ§\n",
      "Ù†ÙƒØ³Ø± ÙÙŠ Ø­ÙƒÙ… Ù†Ø¨ÙŠ Ù¨\n",
      "ØªÙˆØ­Ø´ØªÙƒ Ø¹Ø±ÙØª ÙƒÙ„Ø§Ù…ÙŠ Ø§Ù†Ø§ Ù„Ø§\n",
      "Ø¨Ø¬Ø¨ÙˆØ¬ Ø¯Ù…Ø¯ÙˆÙ… Ø§Ù„Ø¹Ù„ÙˆØ´ ØªØ¨Ø§Ø±Ùƒ Ø§Ù„Ù„Ù‡\n",
      "ÙˆØ§Ù„Ø§ Ù†Ø³ØªÙØ²Ù‡ØŸ Ù‚ØªÙ„Ùˆ Ø¨Ø§Ø´ ÙŠØ±ÙƒØ¨Ùƒ\n",
      "ÙŠÙˆÙ… ÙˆØ§Ù‚Ù Ø­Ø±ÙŠÙ‡ Ø§Ù„Ø§Ø®Ø±ÙŠÙ† ÙˆÙŠÙ‚ÙˆÙ„\n",
      "Ù…Ø²Ø§Ù„ Ù„ØªÙˆÙ‡ Ù…Ø§ ÙŠÙ‚ÙˆÙ„Ùˆ ÙŠØ±ÙˆØ­\n",
      "Ø·Ø§Ù„Ø¨Ù‡ ÙŠØ­ÙƒÙ… ØºØ§ÙŠØ±ÙŠÙ† Ù…Ø§ Ø¹Ù„ÙŠÙ‡\n",
      "ÙˆØ¨ØºÙ„Ù‡ Ø¹Ø§Ø¯ÙŠ Ù…Ø´ Ø¹Ù†Ø¯ÙˆØ´ Ù…Ø¨Ø¯Ø§\n",
      "ØªØªØ¹Ø§Ù„Ø¬Ùˆ Ø¨Ø§Ø´ Ø§Ù„Ø§Ù„Ù‡ Ø§Ø±Ø²Ø¹ Ø¨Ù„ÙˆÙƒØ§Øª\n",
      "Ù…Ø´ Ù…Ø¬Ø¨ÙˆØ± Ù‡ÙŠØ§ ØªØ¹Ø§Ù„ ØµØ¯Ù‚ÙˆÙ†ÙŠ\n",
      "Ùˆ Ø§Ø§Ø§Ù„ Ù…Ø­Ù…Ø§Ø§Ø§Ø¯ ØŒ ÙƒÙŠÙØ§Ù‡\n",
      "ØªÙÙŠÙ‚Ù†ÙŠ Ø¨Ø§Ù„Ù„ÙŠ ØµØ§ÙŠØ± ÙÙŠ Ø§Ù„ÙØ§ØªØ­Ù‡\n",
      "Ù„Ù„Ø§Ø®Ø± Ù…Ù†ØªØ®Ø¨Ù†Ø§ ÙØ±Ø§ÙŠØ¬ÙŠ Ø±Ù‚Ø¯ Ùˆ\n",
      "Ø§Ù„Ù…Ù‡Ù… Ø¹Ø²Ø§Ø¡ Ù„Ù„Ø´Ø§Ù…ØªÙŠÙ† ÙˆÙ…Ù† Ø§Ù„Ù‚Ù„Ø¨\n",
      "ÙˆÙ„ØµÙˆØµ ÙˆØ®ÙˆÙ†Ù‡ Ù†Ø¬Ù…Ù‡ Ù†ØµØ±Ø§ÙˆÙŠ ÙˆØ±Ø§Ù…ÙˆØ³\n",
      "ÙˆØ±Ø§Ù‡ ÙØµÙ„ ÙˆØ³Ø¹ Ø§Ù„Ù‚Ø±ÙˆÙŠ Ø¨Ø§Ø´\n",
      "ØªØ³Ø§Ø³ÙŠ Ø§Ù„Ù„ÙŠ Ø§ÙŠØ¯Øª Ù‚Ø±Ø§Ø± ÙÙˆØ¶ÙŠ\n",
      "Ø®Ù„Ù„ÙŠÙ†Ø§ Ø²Ø±Ù‚Ù‡ Ø§Ù†Ùƒ ÙŠÙ‚ÙˆÙ„ Ø§Ù„Ø¸Ù„Ù…\n",
      "ÙŠØ¹Ù…Ù„ÙˆØŒ Ø¹Ù„ÙŠ Ø±Ø§Ø³Ùˆ Ù…Ø§Ù†ÙŠØ´ ÙŠÙˆÙ„ÙŠ\n",
      "Ø±Ø§Ø­Ù‡ Ø§Ù„Ø¨Ø§Ù„ Ø§Ù„Ù…Ø¯Ù† Ø¹Ù†Ø¯ÙŠØŒ Ù…Ù†\n",
      "Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠÙ‡ Ø­Ø§Ø¬Ù‡ Ù…Ù† Ø¶Ø±Ø¨Ù‡ Ø§Ù„Ø§Ù…Ø§Ø±Ø§Øª\n",
      "ÙØ§Ø´Ø­Ù‡ Ù…Ø§ÙƒÙ„Ù‡ Ø§ÙˆÙ„Ø§Ø¯ Ø¨Ù„Ø§Ø¯ÙŠ ØªÙˆÙ†Ø³\n",
      "Ø¶Ø§ÙŠØ¹ Ù†ØªÙŠØ¬Ù‡ Ø§Ù„Ø¹ÙÙ† Ø§Ø­Ù‚Ø± Ù…Ø§Ø²Ø§Ù„\n",
      "Ù‡ÙˆÙ…Ø§ Ø±Ø§Ø¨Ø­ÙŠÙ† Ø¹Ù†Ø¯Ùˆ Ù†Ù‡Ø§Ø± Ø§Ù„Ø³Ø¨Øª\n",
      "Ø¯ÙˆÙ„ ÙˆÙ„Ø§ ÙŠØ´ÙƒÙŠÙ„Ùˆ Ø®Ù„ ÙŠØºÙ†ÙŠ\n",
      "ÙƒÙŠÙ† Ø§Ù„Ù…Ø±Ø§ÙˆÙ„ Ùˆ Ø®Ù„Ø¹Ù†Ø§ Ø§Ù„Ø¯Ù†ÙŠØ§\n",
      "Ø§Ø¬Ø§ Ø¨Ø§Ø´ Ø³ÙˆÙŠÙ‚Ù‡ Ø¨Ø¬Ø¯Ùƒ ØªØ­ÙƒÙŠ\n",
      "Ù„Ù…Ø§ Ù‡Ø§Ù„Ø§Ø®Ø¨Ø§Ø± Ø§Ù„Ù„ÙŠ Ø¹Ø§ÙŠØ´ÙŠÙ† ÙÙŠ\n",
      "ØªØ³Ø±Ù‚Ùˆ ÙÙŠ Ø§Ù„Ø²ÙŠØªÙˆÙ†Ù‡ Ùˆ Ù…Ù‡Ø¯Ø¯\n",
      "Ø¨ÙŠØ¹Ù‡ ØªØ­ÙŠØ§ ØªÙˆÙ†Ø³ Ø§Ù„Ø¹Ø²ÙŠØ²Ù‡ Ø¯ÙƒØªÙˆØ±ØªÙ†Ø§\n",
      "Ø§Ø²Ø§ÙŠ ÙˆÙ‡Ùˆ Ù‚Ù„Øª Ø§Ù„ØªÙ‡ÙŠÙˆØ§Øª Ø±Ø¬Ø¹Øª\n",
      "Ùˆ Ø®Ùˆ ÙƒØ§ØªÙ„ÙˆÙ†ÙŠØ§ Ø§Ù‡Ù… Ø´ÙŠ\n",
      "ØªØªÙƒÙ„Ù Ø¹Ø¯ Ø´ÙØª Ø±Ø¨ÙŠ ÙŠØ´Ù…Ù„Ù†Ø§\n",
      "Ø§Ù„Ø¯ÙØ§Ø¹ ÙÙ† Ø§Ø±ØªØ­Øª Ù…Ù† Ø§Ù„Ù„ÙŠØ³ÙŠ\n",
      "Ù„Ø­Ø¯Ø§Ø«ÙŠÙŠÙ† ÙŠØ§ Ø¹Ø¨Ø§Ø³ ÙŠØ§ Ø¬Ù…Ø§Ø¹Ù‡\n",
      "Ù…Ø¹Ø§Ù‡ Ù†Ù‚ÙˆÙ„ ÙŠÙˆÙƒØ¯ Ø¨Ø§Ø´ Ù†ØµÙˆØªÙ„Ùƒ\n",
      "Ù…Ù† Ø³Ù†ÙŠÙ†ÙŠ ÙƒØ±Ù…Ø§Ù„ÙŠ Ø²Ø§ÙŠØ¯ Ù‚Ø§Ù„Ù‘Ùƒ\n",
      "Ù‡ÙŠ Ø§Ù„Ø³ÙƒÙˆØªØ´ ØªÙˆ ØªØ¹Ù…Ù„ÙˆÙ†Ù†Ø§ Ø¹Ù…Ù„Ù‡\n",
      "Ø¬Ø§ÙˆØ¨Ùˆ Ø§Ù„Ø¹ØµÙÙˆØ± Ø§Ù„ØµÙ‘ØºÙŠØ± Ù„ÙŠ Ù‡Ùˆ\n",
      "ÙŠØµØ­Ùˆ Ø¹Ù†Ø¯Ùƒ ÙˆÙ„Ø§ÙˆØ¬Ø¹ Ø±Ø§Ø³ Ø§Ø³ØªØ§Ø°Ù†ÙƒÙ…\n",
      "Ø§Ù„Ø¬Ø²Ø§ÙŠØ± ÙˆØ§Ø­Ø¯ Ø¯Ø¹Ø§Ù‡ ØªØªØ¹Ù…Ù… Ø¹Ù„ÙŠ\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    print(generate_text(model, start_string=''))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
